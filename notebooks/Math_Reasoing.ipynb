{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1768568234526,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "j7dofMDUgauj"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1768568237826,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "BAPHMTtYjB8p",
    "outputId": "67b282e0-359a-45b7-bcca-18dc71fef580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 8000 math problems.\n",
      "First 5 problems:\n",
      "('8 * 14 * 3', 336)\n",
      "('7 * 15 + 12', 117)\n",
      "('7 * 9 * 13', 819)\n",
      "('3 + 3 + 5', 11)\n",
      "('13 * 6 + 10', 88)\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "\n",
    "for _ in range(8000):\n",
    "    a = random.randint(1, 15)\n",
    "    b = random.randint(1, 15)\n",
    "    c = random.randint(1, 15)\n",
    "\n",
    "    op1 = random.choice(['+', '*'])\n",
    "    op2 = random.choice(['+', '*'])\n",
    "\n",
    "    exp = f\"{a} {op1} {b} {op2} {c}\"\n",
    "\n",
    "    try:\n",
    "        ans = eval(exp)\n",
    "    except Exception as e:\n",
    "        ans = f\"Error: {e}\"\n",
    "\n",
    "    train_data.append((exp, ans))\n",
    "\n",
    "print(f\"Generated {len(train_data)} math problems.\")\n",
    "print(\"First 5 problems:\")\n",
    "for i in range(min(5, len(train_data))):\n",
    "    print(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1768568241191,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "BH7HJZeQm3V-",
    "outputId": "c3ec61fb-e70b-480b-980d-29b98e2bcad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2000 math problems.\n",
      "First 5 problems:\n",
      "('11 * 4 * 12', 528)\n",
      "('3 * 5 + 15', 30)\n",
      "('9 * 5 + 5', 50)\n",
      "('15 + 8 * 3', 39)\n",
      "('7 + 4 + 11', 22)\n"
     ]
    }
   ],
   "source": [
    "val_data = []\n",
    "\n",
    "for _ in range(2000):\n",
    "    a = random.randint(1, 15)\n",
    "    b = random.randint(1, 15)\n",
    "    c = random.randint(1, 15)\n",
    "\n",
    "    op1 = random.choice(['+', '*'])\n",
    "    op2 = random.choice(['+', '*'])\n",
    "\n",
    "    exp = f\"{a} {op1} {b} {op2} {c}\"\n",
    "\n",
    "    try:\n",
    "        ans = eval(exp)\n",
    "    except Exception as e:\n",
    "        ans = f\"Error: {e}\"\n",
    "\n",
    "    val_data.append((exp, ans))\n",
    "\n",
    "print(f\"Generated {len(val_data)} math problems.\")\n",
    "print(\"First 5 problems:\")\n",
    "for i in range(min(5, len(val_data))):\n",
    "    print(val_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1768568243607,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "w-Vymmg9nu-g",
    "outputId": "15186a32-e75b-48da-8896-5cb682b7daf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2000 math problems.\n",
      "First 5 problems:\n",
      "('16 + 16 * 18', 304)\n",
      "('16 * 18 * 20', 5760)\n",
      "('20 * 16 + 20', 340)\n",
      "('16 * 18 * 19', 5472)\n",
      "('16 * 16 + 16', 272)\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "\n",
    "for _ in range(2000):\n",
    "    a = random.randint(16, 20)\n",
    "    b = random.randint(16, 20)\n",
    "    c = random.randint(16, 20)\n",
    "\n",
    "    op1 = random.choice(['+', '*'])\n",
    "    op2 = random.choice(['+', '*'])\n",
    "\n",
    "    exp = f\"{a} {op1} {b} {op2} {c}\"\n",
    "\n",
    "    # Using try-except for eval to handle potential errors, though unlikely with simple math\n",
    "    try:\n",
    "        ans = eval(exp)\n",
    "    except Exception as e:\n",
    "        ans = f\"Error: {e}\"\n",
    "\n",
    "    test_data.append((exp, ans))\n",
    "\n",
    "print(f\"Generated {len(test_data)} math problems.\")\n",
    "print(\"First 5 problems:\")\n",
    "for i in range(min(5, len(test_data))):\n",
    "    print(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1768568245736,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "b2720f72",
    "outputId": "bd09cbad-4a37-4865-d508-4af9436794ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8000\n",
      "Val size: 2000\n",
      "Test size: 2000\n",
      "Train example: ('8 * 14 * 3', 336)\n",
      "Test example (16-20 range): ('16 + 16 * 18', 304)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size:\", len(train_data))\n",
    "print(\"Val size:\", len(val_data))\n",
    "print(\"Test size:\", len(test_data))\n",
    "\n",
    "print(\"Train example:\", train_data[0])\n",
    "print(\"Test example (16-20 range):\", test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1768568247610,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "fvXxOY2QqX8f",
    "outputId": "68a4a41a-dc01-49c3-a9fb-3d9874a39724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, '+': 13, '*': 14, ' ': 15}\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    '<PAD>': 0,\n",
    "    '<SOS>': 1,\n",
    "    '<EOS>': 2,\n",
    "}\n",
    "\n",
    "for i in range(10):\n",
    "  vocab[str(i)] = i + 3\n",
    "\n",
    "\n",
    "vocab['+'] = 13\n",
    "vocab['*'] = 14\n",
    "vocab[' '] = 15\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1768568249877,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "0bc62ccb",
    "outputId": "b7b941b4-a21f-46cb-d525-14ec867b458c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD>\n",
      "2\n",
      "+\n"
     ]
    }
   ],
   "source": [
    "idx_to_char = {v: k for k, v in vocab.items()}\n",
    "\n",
    "print(idx_to_char[0])\n",
    "print(idx_to_char[5])\n",
    "print(idx_to_char[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1768568251931,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "XwBWqc7Nuqra",
    "outputId": "36d1d3d2-45a5-45b2-b751-74c7932dc869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3 + 5' -> [6, 15, 13, 15, 8]\n"
     ]
    }
   ],
   "source": [
    "def encode(text, vocab):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for char in text:\n",
    "        if char in vocab:\n",
    "            results.append(vocab[char])\n",
    "\n",
    "        else:\n",
    "            print(f\"character '{char}' not found in vocab.\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "test = \"3 + 5\"\n",
    "encoded = encode(test, vocab)\n",
    "print(f\"'{test}' -> {encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1768568253823,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "718692ba",
    "outputId": "41ff2134-dedf-4adb-8ca0-d07de2ba20eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'[6, 15, 13, 15, 8]' -> '3 + 5'\n"
     ]
    }
   ],
   "source": [
    "def decode(indices, idx_to_char):\n",
    "    results = []\n",
    "    for idx in indices:\n",
    "        if idx in idx_to_char:\n",
    "            results.append(idx_to_char[idx])\n",
    "        else:\n",
    "            print(f\"Index '{idx}' not found in idx_to_char.\")\n",
    "    return ''.join(results)\n",
    "\n",
    "# Test the decode function with the previously encoded '3 + 5'\n",
    "decoded = decode(encoded, idx_to_char)\n",
    "print(f\"'{encoded}' -> '{decoded}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "380cbbd6"
   },
   "source": [
    "Q1: Should input and output be same length?\n",
    "\n",
    "No, input and output generally won't be the same length. Sequence-to-sequence models handle this.\n",
    "\n",
    "Q2: Where do we add and tokens?\n",
    "\n",
    "Input Expression: Don't usually add them.\n",
    "Output Answer: Add SOS at the beginning and EOS at the end to guide the decoder.\n",
    "\n",
    "Q3: What's the maximum length we should pad to?\n",
    "\n",
    "Find the absolute longest input expression and longest output answer (as a string) across all data. These maximums generally define max_sequence_length, possibly with a small buffer or using a high percentile for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1768568255854,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "Rotq-OCJYu-i",
    "outputId": "56b36f5c-7285-4ba5-bd56-78b2d5e758b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input lenght:  12\n",
      "Max output lenght:  4\n"
     ]
    }
   ],
   "source": [
    "max_input_len = 0\n",
    "max_output_len = 0\n",
    "\n",
    "all_data = train_data + val_data + test_data\n",
    "\n",
    "for expr, ans in all_data:\n",
    "\n",
    "  input_len = len(expr)\n",
    "\n",
    "  if input_len > max_input_len:\n",
    "    max_input_len = input_len\n",
    "\n",
    "  output_len = len(str(ans))\n",
    "\n",
    "  if output_len > max_output_len:\n",
    "    max_output_len = output_len\n",
    "\n",
    "\n",
    "print(f\"Max input lenght: \", max_input_len)\n",
    "\n",
    "print(f\"Max output lenght: \", max_output_len)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bHe6HiieaV6"
   },
   "source": [
    "padded lengths\n",
    "\n",
    "For Input:\n",
    "\n",
    "20 (round number with buffer)\n",
    "\n",
    "For Output (with SOS/EOS):\n",
    "\n",
    "Max answer: 4 chars\n",
    "\n",
    "Add SOS at start: +1\n",
    "\n",
    "Add EOS at end: +1\n",
    "\n",
    "Total needed: 10(buffer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1768568259239,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "Bi7sL1PpbwiL",
    "outputId": "eae487ac-caeb-451a-e7c0-f58e7852d942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 20\n",
      "Padded length: 20\n",
      "Padded: [6, 15, 13, 15, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def pad_sequence(sequence, max_len, pad_token = 0):\n",
    "\n",
    "  if len(sequence) > max_len:\n",
    "    sequence = sequence[:max_len]\n",
    "\n",
    "  padding = max_len - len(sequence)\n",
    "\n",
    "  for i in range(padding):\n",
    "\n",
    "    sequence.append(pad_token) # Corrected: use list's append method\n",
    "\n",
    "\n",
    "  return sequence\n",
    "\n",
    "\n",
    "test_seq = [6, 15, 13, 15, 8]\n",
    "padded = pad_sequence(test_seq, max_len = 20, pad_token=0)\n",
    "\n",
    "print(f\"Original length: {len(test_seq)}\")\n",
    "print(f\"Padded length: {len(padded)}\")\n",
    "print(f\"Padded: {padded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1768568261084,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "HfQXapLpjD3l",
    "outputId": "300ffeb2-2855-4c8d-bb2f-c2b84e62206f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: 5, 20\n",
      "Decoder input shape: 5, 10\n",
      "Decoder target shape: 5, 10\n",
      "\n",
      "Example:\n",
      "Expression: 8 * 14 * 3\n",
      "Encoder: [11, 15, 14, 15, 4, 7, 15, 14, 15, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Dec Input: [1, 6, 6, 9, 0, 0, 0, 0, 0, 0]\n",
      "Dec Target: [6, 6, 9, 2, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(dataset, char_to_idx, max_input_len, max_output_len):\n",
    "\n",
    "  encoder_inputs = []\n",
    "  decoder_inputs = []\n",
    "  decoder_target = []\n",
    "\n",
    "  for expr, ans in dataset:\n",
    "\n",
    "    enc_input = encode(expr, char_to_idx)\n",
    "    # Corrected: Encoder input should be padded to max_input_len\n",
    "    enc_input = pad_sequence(enc_input, max_input_len)\n",
    "\n",
    "    dec_input = [char_to_idx['<SOS>']] + encode(str(ans), char_to_idx)\n",
    "    dec_input = pad_sequence(dec_input, max_output_len)\n",
    "\n",
    "    dec_target = encode(str(ans), char_to_idx) + [char_to_idx['<EOS>']]\n",
    "    dec_target = pad_sequence(dec_target, max_output_len)\n",
    "\n",
    "    encoder_inputs.append(enc_input)\n",
    "    decoder_inputs.append(dec_input)\n",
    "    decoder_target.append(dec_target)\n",
    "\n",
    "  return encoder_inputs, decoder_inputs, decoder_target\n",
    "\n",
    "max_input_len = 20\n",
    "max_output_len = 10\n",
    "\n",
    "train_enc, train_dec_in, train_dec_out = prepare_data(\n",
    "    dataset=train_data[:5],\n",
    "    char_to_idx=vocab,\n",
    "    max_input_len=max_input_len,\n",
    "    max_output_len=max_output_len\n",
    "  )\n",
    "\n",
    "\n",
    "print(f\"Encoder input shape: {len(train_enc)}, {len(train_enc[0])}\")\n",
    "print(f\"Decoder input shape: {len(train_dec_in)}, {len(train_dec_in[0])}\")\n",
    "print(f\"Decoder target shape: {len(train_dec_out)}, {len(train_dec_out[0])}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"Expression: {train_data[0][0]}\")\n",
    "print(f\"Encoder: {train_enc[0]}\")\n",
    "print(f\"Dec Input: {train_dec_in[0]}\")\n",
    "print(f\"Dec Target: {train_dec_out[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1768568263650,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "bNVZlAT2nkpg",
    "outputId": "fc7bf30b-2103-474f-fa5f-959672acd0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing full datasets...\n",
      "Train: 8000 samples\n",
      "Val: 2000 samples\n",
      "Test: 2000 samples\n"
     ]
    }
   ],
   "source": [
    "# Process all datasets (remove the [:5] slice)\n",
    "print(\"Processing full datasets...\")\n",
    "\n",
    "train_enc, train_dec_in, train_dec_out = prepare_data(\n",
    "    train_data, vocab, max_input_len, max_output_len\n",
    ")\n",
    "\n",
    "val_enc, val_dec_in, val_dec_out = prepare_data(\n",
    "    val_data, vocab, max_input_len, max_output_len\n",
    ")\n",
    "\n",
    "test_enc, test_dec_in, test_dec_out = prepare_data(\n",
    "    test_data, vocab, max_input_len, max_output_len\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_enc)} samples\")\n",
    "print(f\"Val: {len(val_enc)} samples\")\n",
    "print(f\"Test: {len(test_enc)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4039,
     "status": "ok",
     "timestamp": 1768568269471,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "kOvtRDdJ8tT5",
    "outputId": "298f0142-03a2-4549-8790-3874b58da601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encoder shape: torch.Size([8000, 20])\n",
      "Train decoder input shape: torch.Size([8000, 10])\n",
      "Train decoder target shape: torch.Size([8000, 10])\n",
      "Val encoder shape: torch.Size([2000, 20])\n",
      "Val decoder input shape: torch.Size([2000, 10])\n",
      "Val decoder target shape: torch.Size([2000, 10])\n",
      "Test encoder shape: torch.Size([2000, 20])\n",
      "Test decoder input shape: torch.Size([2000, 10])\n",
      "Test decoder target shape: torch.Size([2000, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_enc = torch.LongTensor(np.array(train_enc))\n",
    "train_dec_in = torch.LongTensor(np.array(train_dec_in))\n",
    "train_dec_out = torch.LongTensor(np.array(train_dec_out))\n",
    "\n",
    "test_enc = torch.LongTensor(np.array(test_enc))\n",
    "test_dec_in = torch.LongTensor(np.array(test_dec_in))\n",
    "test_dec_out = torch.LongTensor(np.array(test_dec_out))\n",
    "\n",
    "val_enc = torch.LongTensor(np.array(val_enc))\n",
    "val_dec_in = torch.LongTensor(np.array(val_dec_in))\n",
    "val_dec_out = torch.LongTensor(np.array(val_dec_out))\n",
    "\n",
    "print(\"Train encoder shape:\", train_enc.shape)\n",
    "print(\"Train decoder input shape:\", train_dec_in.shape)\n",
    "print(\"Train decoder target shape:\", train_dec_out.shape)\n",
    "\n",
    "print(\"Val encoder shape:\", val_enc.shape)\n",
    "print(\"Val decoder input shape:\", val_dec_in.shape)\n",
    "print(\"Val decoder target shape:\", val_dec_out.shape)\n",
    "\n",
    "print(\"Test encoder shape:\", test_enc.shape)\n",
    "print(\"Test decoder input shape:\", test_dec_in.shape)\n",
    "print(\"Test decoder target shape:\", test_dec_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1768568271752,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "jCNMkI2rPUvD",
    "outputId": "1d4279e9-066b-46fb-8b48-ed068efa35a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(16, 128)\n",
      "  (lstm): LSTM(128, 256, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "     super(Encoder, self).__init__()\n",
    "\n",
    "     # Create embedding layer\n",
    "     self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "     # Create LSTM layer\n",
    "     self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                         hidden_size=hidden_dim,\n",
    "                         batch_first=True)\n",
    "\n",
    "  def forward(self, input_seq):\n",
    "\n",
    "    # embed input\n",
    "    embedded = self.embedding(input_seq)\n",
    "\n",
    "    # pass through lstm\n",
    "    output, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "    return hidden, cell\n",
    "\n",
    "\n",
    "vocab_size = 16\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1768568275785,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "-WwqOv8BTUhH",
    "outputId": "1492dab3-d98f-4325-a956-bf2ae614f359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (embedding): Embedding(16, 128)\n",
      "  (lstm): LSTM(128, 256, batch_first=True)\n",
      "  (fc): Linear(in_features=256, out_features=16, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "     super(Decoder, self).__init__()\n",
    "\n",
    "     # EMbeddding layer\n",
    "     self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "     # Lstm layer\n",
    "     self.lstm = nn.LSTM(embedding_dim,\n",
    "                         hidden_dim,\n",
    "                         batch_first= True)\n",
    "\n",
    "     # output projected layer\n",
    "     self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "  def forward(self, input_seq, hidden, cell):\n",
    "\n",
    "    # Embed input\n",
    "    embedded = self.embedding(input_seq)\n",
    "\n",
    "    # Pass through lstm with encoder states\n",
    "    outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "\n",
    "    predictions = self.fc(outputs)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "decoder = Decoder(vocab_size = 16, embedding_dim= 128, hidden_dim=256)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1768568280057,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "mkXo9dEKWMFy",
    "outputId": "ddb17e08-d9f1-49e2-e2ec-305b6df846e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(16, 128)\n",
      "    (lstm): LSTM(128, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(16, 128)\n",
      "    (lstm): LSTM(128, 256, batch_first=True)\n",
      "    (fc): Linear(in_features=256, out_features=16, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total Parameters: 798736\n"
     ]
    }
   ],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "     super().__init__() # Corrected: Added 'self' implicitly with modern super() call\n",
    "\n",
    "     # store encoder and decoder\n",
    "\n",
    "     self.encoder = encoder\n",
    "     self.decoder = decoder\n",
    "\n",
    "  def forward(self, src, trg):\n",
    "\n",
    "    # encode source seq\n",
    "    hidden, cell = self.encoder(src)\n",
    "\n",
    "    # decode with encoder context\n",
    "    output = self.decoder(trg, hidden, cell)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_size=16, embedding_dim=128, hidden_dim=256)\n",
    "decoder = Decoder(vocab_size=16, embedding_dim=128, hidden_dim=256)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "print(model)\n",
    "print(\"\\nTotal Parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1768568286281,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "ov02NEEZYfxh",
    "outputId": "d261926a-58b3-49e7-d85a-c29d3101250d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 63\n",
      "Validation batches: 16\n",
      "Test batches: 16\n",
      "\n",
      "Batch shapes:\n",
      "  Encoder input: torch.Size([128, 20])\n",
      "  Decoder input: torch.Size([128, 10])\n",
      "  Decoder target: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# create Tensor datasets\n",
    "train_dataset = TensorDataset(train_enc, train_dec_in, train_dec_out)\n",
    "val_dataset = TensorDataset(val_enc, val_dec_in, val_dec_out)\n",
    "test_dataset = TensorDataset(test_enc, test_dec_in, test_dec_out)\n",
    "\n",
    "# create Dataloader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size= batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "for batch in train_loader:\n",
    "  enc_input, dec_input, dec_target = batch\n",
    "  print(f\"\\nBatch shapes:\")\n",
    "  print(f\"  Encoder input: {enc_input.shape}\")\n",
    "  print(f\"  Decoder input: {dec_input.shape}\")\n",
    "  print(f\"  Decoder target: {dec_target.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6983,
     "status": "ok",
     "timestamp": 1768568295816,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "sHVl2F6zmKP9",
    "outputId": "0bfa4ea4-2cd9-48a3-9b5a-cf4d8c0e7b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loss function: CrossEntropyLoss (ignoring index 0)\n",
      "Optimizer: Adam (lr=0.001)\n",
      "Model parameters: 798,736\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Loss function: CrossEntropyLoss (ignoring index 0)\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8033,
     "status": "ok",
     "timestamp": 1768568314360,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "amTqJCj4r6bB",
    "outputId": "cd6436a1-4090-4592-91e6-303ed44530a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch    Train Loss   Val Loss     Best    \n",
      "---------------------------------------------\n",
      "1        1.8015       1.6241       ✓       \n",
      "2        1.5494       1.4744       ✓       \n",
      "3        1.4220       1.3696       ✓       \n",
      "4        1.2979       1.2342       ✓       \n",
      "5        1.1754       1.1506       ✓       \n",
      "6        1.0715       1.0268       ✓       \n",
      "7        0.9607       0.9280       ✓       \n",
      "8        0.8814       0.8960       ✓       \n",
      "9        0.7891       0.7604       ✓       \n",
      "10       0.7039       0.6747       ✓       \n",
      "11       0.6359       0.6433       ✓       \n",
      "12       0.6050       0.6267       ✓       \n",
      "13       0.5727       0.5602       ✓       \n",
      "14       0.5230       0.5425       ✓       \n",
      "15       0.4768       0.5264       ✓       \n",
      "16       0.4652       0.4611       ✓       \n",
      "17       0.4185       0.4387       ✓       \n",
      "18       0.3948       0.4144       ✓       \n",
      "19       0.3714       0.3992       ✓       \n",
      "20       0.3491       0.3744       ✓       \n",
      "\n",
      "Training complete!\n",
      "Best validation loss: 0.3744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=20):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    print(f\"{'Epoch':<8} {'Train Loss':<12} {'Val Loss':<12} {'Best':<8}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        is_best = val_loss < best_val_loss\n",
    "        if is_best:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "        best_marker = \"✓\" if is_best else \"\"\n",
    "        print(f\"{epoch+1:<8} {train_loss:<12.4f} {val_loss:<12.4f} {best_marker:<8}\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "# Run training\n",
    "train_losses, val_losses = train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    num_epochs=20\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, pad_idx=0):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for enc_input, dec_input, dec_target in dataloader:\n",
    "            enc_input = enc_input.to(device)\n",
    "            dec_input = dec_input.to(device)\n",
    "            dec_target = dec_target.to(device)\n",
    "            \n",
    "            output = model(enc_input, dec_input)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), dec_target.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1768568320762,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "ygjWfUxAum44",
    "outputId": "886dea83-3341-4a2b-d7a2-262aa480dec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model (epoch 18)\n",
      "\n",
      "Test Loss (Zero-Shot 16-20): 5.1731\n",
      "Validation Loss (1-15): 0.4144\n",
      "\n",
      "Difference: 4.7588\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "print(\"Loaded best model (epoch 18)\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest Loss (Zero-Shot 16-20): {test_loss:.4f}\")\n",
    "print(f\"Validation Loss (1-15): {val_losses[17]:.4f}\")  # Epoch 18\n",
    "print(f\"\\nDifference: {test_loss - val_losses[17]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1768568323067,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "BUaZLmqyuxhJ",
    "outputId": "ffe758e9-6ed5-4218-ae0d-8ee160d1a83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PREDICTIONS ON TRAINING RANGE (1-15):\n",
      "==================================================\n",
      "3 + 5           → Predicted: 13       Actual: 8        ✗\n",
      "2 * 4           → Predicted: 16       Actual: 8        ✗\n",
      "5 + 3 * 2       → Predicted: 11       Actual: 11       ✓\n",
      "10 + 5          → Predicted: 23       Actual: 15       ✗\n",
      "7 * 2           → Predicted: 24       Actual: 14       ✗\n",
      "\n",
      "==================================================\n",
      "PREDICTIONS ON TEST RANGE (16-20) - ZERO SHOT:\n",
      "==================================================\n",
      "16 + 18         → Predicted: 34       Actual: 34       ✓\n",
      "17 * 2          → Predicted: 132      Actual: 34       ✗\n",
      "19 + 20         → Predicted: 25       Actual: 39       ✗\n",
      "16 * 18         → Predicted: 118      Actual: 288      ✗\n",
      "20 + 17 * 2     → Predicted: 28       Actual: 54       ✗\n"
     ]
    }
   ],
   "source": [
    "def predict(model, expression, vocab, idx_to_char, max_len=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Predict answer for a single expression\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Encode expression\n",
    "    encoded = encode(expression, vocab)\n",
    "    padded = pad_sequence(encoded, 20, 0)\n",
    "\n",
    "    # To tensor\n",
    "    src = torch.LongTensor([padded]).to(device)  # [1, 20]\n",
    "\n",
    "    # Get encoder context\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src)\n",
    "\n",
    "    # Start with <SOS>\n",
    "    decoder_input = torch.LongTensor([[vocab['<SOS>']]]).to(device)  # [1, 1]\n",
    "\n",
    "    output_sequence = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            output = model.decoder(decoder_input, hidden, cell)\n",
    "\n",
    "        # Get prediction for last position\n",
    "        pred_token = output[:, -1, :].argmax(dim=-1).item()\n",
    "\n",
    "        # Stop if <EOS>\n",
    "        if pred_token == vocab['<EOS>']:\n",
    "            break\n",
    "\n",
    "        output_sequence.append(pred_token)\n",
    "\n",
    "        # Next input is current prediction\n",
    "        decoder_input = torch.cat([decoder_input,\n",
    "                                   torch.LongTensor([[pred_token]]).to(device)],\n",
    "                                  dim=1)\n",
    "\n",
    "    # Decode\n",
    "    predicted = decode(output_sequence, idx_to_char)\n",
    "    return predicted\n",
    "\n",
    "# Test on training range (1-15)\n",
    "print(\"=\" * 50)\n",
    "print(\"PREDICTIONS ON TRAINING RANGE (1-15):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_expressions = [\n",
    "    \"3 + 5\",\n",
    "    \"2 * 4\",\n",
    "    \"5 + 3 * 2\",\n",
    "    \"10 + 5\",\n",
    "    \"7 * 2\"\n",
    "]\n",
    "\n",
    "for expr in test_expressions:\n",
    "    predicted = predict(model, expr, vocab, idx_to_char, device=device)\n",
    "    actual = str(eval(expr))\n",
    "    correct = \"✓\" if predicted == actual else \"✗\"\n",
    "    print(f\"{expr:<15} → Predicted: {predicted:<8} Actual: {actual:<8} {correct}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PREDICTIONS ON TEST RANGE (16-20) - ZERO SHOT:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_expressions_zeroshot = [\n",
    "    \"16 + 18\",\n",
    "    \"17 * 2\",\n",
    "    \"19 + 20\",\n",
    "    \"16 * 18\",\n",
    "    \"20 + 17 * 2\"\n",
    "]\n",
    "\n",
    "for expr in test_expressions_zeroshot:\n",
    "    predicted = predict(model, expr, vocab, idx_to_char, device=device)\n",
    "    actual = str(eval(expr))\n",
    "    correct = \"✓\" if predicted == actual else \"✗\"\n",
    "    print(f\"{expr:<15} → Predicted: {predicted:<8} Actual: {actual:<8} {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26830,
     "status": "ok",
     "timestamp": 1768568360737,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "QtwZQ0ZFvRU2",
    "outputId": "dee0ab97-096a-4439-c1b6-dd5054b2e47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracies...\n",
      "This may take a few minutes...\n",
      "\n",
      "==================================================\n",
      "FINAL RESULTS:\n",
      "==================================================\n",
      "Training Accuracy (1-15):   63.49%\n",
      "Validation Accuracy (1-15): 59.25%\n",
      "Test Accuracy (16-20):      0.00%\n",
      "\n",
      "Generalization Gap: 59.25%\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, dataloader, vocab, idx_to_char, device):\n",
    "    \"\"\"Calculate exact match accuracy\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        enc_input, _, dec_target = batch\n",
    "        enc_input = enc_input.to(device)\n",
    "\n",
    "        for i in range(enc_input.size(0)):\n",
    "            # Get expression\n",
    "            expr_indices = enc_input[i].cpu().tolist()\n",
    "            expr = decode([idx for idx in expr_indices if idx not in [0, 1, 2]], idx_to_char)\n",
    "\n",
    "            # Get actual answer\n",
    "            target_indices = dec_target[i].cpu().tolist()\n",
    "            actual = decode([idx for idx in target_indices if idx not in [0, 1, 2]], idx_to_char)\n",
    "\n",
    "            # Predict\n",
    "            try:\n",
    "                predicted = predict(model, expr, vocab, idx_to_char, device=device)\n",
    "                if predicted == actual:\n",
    "                    correct += 1\n",
    "            except:\n",
    "                pass  # Skip if prediction fails\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "print(\"Calculating accuracies...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Train accuracy (sample)\n",
    "train_sample_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "train_acc = calculate_accuracy(model, train_sample_loader, vocab, idx_to_char, device)\n",
    "\n",
    "# Val accuracy\n",
    "val_acc = calculate_accuracy(model, val_loader, vocab, idx_to_char, device)\n",
    "\n",
    "# Test accuracy\n",
    "test_acc = calculate_accuracy(model, test_loader, vocab, idx_to_char, device)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"FINAL RESULTS:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training Accuracy (1-15):   {train_acc:.2f}%\")\n",
    "print(f\"Validation Accuracy (1-15): {val_acc:.2f}%\")\n",
    "print(f\"Test Accuracy (16-20):      {test_acc:.2f}%\")\n",
    "print(f\"\\nGeneralization Gap: {val_acc - test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1768568391278,
     "user": {
      "displayName": "Code Base",
      "userId": "02902497118426624476"
     },
     "user_tz": 300
    },
    "id": "iWIfhQkEvvg-",
    "outputId": "c69b75ff-a53b-450e-c4ed-b9db8499ef4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to lstm_results.json\n",
      "Model saved to best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save final results\n",
    "results = {\n",
    "    'train_acc': 62.04,\n",
    "    'val_acc': 58.45,\n",
    "    'test_acc': 0.00,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'model_params': 798736\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('lstm_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved to lstm_results.json\")\n",
    "print(\"Model saved to best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ldkbwx74RN_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPpsqR+atSnDihL6leO/eiA",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
